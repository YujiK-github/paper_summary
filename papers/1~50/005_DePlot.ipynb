{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DePlot: One-shot visual language reasoning by plot-to-table translation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. どんなもの？\n",
    "one-shot モデルのDeplotの紹介"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 先行研究と比べるとどこが凄い？  \n",
    "* 今まではend2endモデルだったが、(1)画像からグラフや図の情報を抽出してlinearized tableに変換する, (2)LLMに入力して答えを得る.という二段階のモデルにした。End2endモデルを訓練するには大量のデータと計算が必要であり、それでもなお複雑なQuestionについては欠陥があった。Deplotは様々なタイプのタスクにも対応することが出来る。\n",
    "* 新たなchart2tableの評価指標であるRMS, which stands for Relative Mapping Similarityを提案. いままでに使われてきた評価指標であるRNSS, which stands for relative number set similarityは表の中の数字の位置を考慮しないものであった。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. 技術や手法のキモはどこ？\n",
    "* Deplot  \n",
    "  image-to-text encoder-decoder TransformerをSOTAだったMaTCHAのweightに初期化してそこから訓練を始める。tableはマークダウン形式を取っており、セルが別であることを\"|\", 列が離れていることを\"\\n\"で表現する。\n",
    "* LLMのPrompt  \n",
    "  Deplotの出力と質問文を入力する。Chain-of-thoghtで行う。(問に対する答えを出す段階の「思考過程」を学習させる)また、Self-consistencyでも実験を行った。\n",
    "  > [Self-ConsistencyはCoTと同様に思考ステップをPromptの中に例として含めます。Self-Consistencyではさらに1つのPromptに対して複数の回答をLLMに生成させます。](https://techblog.cccmk.co.jp/entry/2023/04/04/102443)\n",
    "* RMS\n",
    "  * 行や列のように置き換えに不変であること、数字や文字の小さなエラーはある程度まで許しpenelizeすること、適合率や再現率の損失を明確に反映させることを考慮して以下の通りに設定する.ただし$r$: row, $c$: columnの値を$v$とする.    \n",
    "  (補足)(1)文章の入力間を適切に測るには Normalized Levenshtein Distance, or $NL_{\\tau}$が使われる.(2)$D_{\\theta}^{p, t}$は1に近いほど類似しており、0に近いほど乖離していることを示す.\n",
    "  \n",
    "  $$\n",
    "  p_{i} = (p_{i}^{r}, p_{i}^{c}, p_{i}^{v}) \\\\\n",
    "  t_{j} = (t_{j}^{r}, t_{j}^{c}, t_{j}^{v}) \\\\\n",
    "  D_{\\tau, \\theta} = (1-NL_{\\tau}(p^{r}||p^{c}, t^{r}||t^{c}))(1-D_{\\theta}(p^{v}, t^{v})) \\\\\n",
    "  \\\\\n",
    "  RMS_{precision} = 1 - \\frac{\\sum_{i=1}^{N}\\sum_{j=1}^{M}X_{ij}D_{\\tau, \\theta}(p_{i}, t_{j})}{N} \\\\\n",
    "  RMS_{recall} = 1 - \\frac{\\sum_{i=1}^{N}\\sum_{j=1}^{M}X_{ij}D_{\\tau, \\theta}(p_{i}, t_{j})}{M}\n",
    "  $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. どうやって有効だと検証した？\n",
    "* 手書きChartQAタスクでSOTA達成(24.0%改善)\n",
    "* ChartQA, PlotQA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 議論はある？\n",
    "* LLMを数値計算やプログラミングに特化させたものにしたらどうなるのだろうか？\n",
    "* chart-to-tableの段階で色や形などの情報が失われてしまうので図の属性を表したものを出力させることを考えないといけない。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 次に読むべき論文は？\n",
    "* ChartOCR\n",
    "* Chain-of-thoght\n",
    "* Self-consistency"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 実装\n",
    "No official code found"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
