{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep State Space Models for Time Series Forecasting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bib\n",
    "@inproceedings{NEURIPS2018_5cf68969,\n",
    " author = {Rangapuram, Syama Sundar and Seeger, Matthias W and Gasthaus, Jan and Stella, Lorenzo and Wang, Yuyang and Januschowski, Tim},\n",
    " booktitle = {Advances in Neural Information Processing Systems},\n",
    " editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},\n",
    " pages = {},\n",
    " publisher = {Curran Associates, Inc.},\n",
    " title = {Deep State Space Models for Time Series Forecasting},\n",
    " url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/5cf68969fb67aa6082363a6d4e6468e2-Paper.pdf},\n",
    " volume = {31},\n",
    " year = {2018}\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. どんなもの？\n",
    "Recurrent neural networkを用いてlinear SSM(Space State Model)のパラメータを特定する方法の提案。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 先行研究と比べるとどこが凄い？  \n",
    "SSMには解釈性は高いものの、複雑な時間経過のパターンを学習させることができなかった。Recurrent neural networkは複雑な時間経過のパターンを学習させることができるが、解釈性が低かった。本研究では、Recurrent neural networkの性質によって複雑な時間経過のパターンを学習し、SSMの性質によって解釈を得ることができる。また、大規模データにも対応し、過学習にも強い。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 技術や手法のキモはどこ？\n",
    "単変量の時系列データ$\\{z_{1:T_{i}}^{(i)} \\}_{i=1}^{T}$が与えられたとする。さらに状態を$\\{\\mathbf{x}_{1:T_{i}+\\tau}^{(i)} \\}_{i=1}^{T}$とする。目的は将来の軌跡の確率分布であり  \n",
    "\n",
    "$$\n",
    "p\\biggl( z_{T_{i}+1:T_{i}+\\tau}^{(i)} \\bigg\\lvert z_{i:T_{i}}^{(i)}, \\mathbf{x}_{i:T_{i}+\\tau}^{i} ; \\Phi \\biggr)\n",
    "$$  \n",
    "  \n",
    "ここでの$\\Phi$は学習させるパラメータ。ここで$\\{1, 2, \\dots, T_{i}\\}$を訓練データ、$\\{T_{i}, T_{i+1}, \\dots, T_{\\tau}\\}$を予測データとする。この論文のアプローチでは$\\Phi$はすべての時点で同じとする。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 状態空間モデル  \n",
    "状態方程式を  \n",
    "\n",
    "$$\n",
    "\\mathbf{l_{t}} = \\mathbf{F_{t}l_{t-1}} + \\bm{g_{t}} \\epsilon_{t}, \\\\\n",
    "\\epsilon \\sim \\mathcal{N}(0, 1), \\\\\n",
    "\\mathbf{l_{0}} \\sim \\mathcal{N}(\\mathbf{\\mu_{0}}, \\text{diag}(\\mathbf{\\sigma}_{0}^2)),\n",
    "$$\n",
    "  \n",
    "とする。ただし、$\\mathbf{F_{t}}$は状態遷移状列、$\\bm{g_{t}}$はinnovation strength。  \n",
    "さらに観測方程式を\n",
    "  \n",
    "$$\n",
    "z_{t} = y_{t} + \\sigma_{t} \\epsilon_{t}, \\\\\n",
    "y_{t} = \\mathbf{a_{t}}^\\top \\bm{l_{t-1}} + b_{t}, \\\\\n",
    "\\epsilon_{t} \\sim \\mathcal{N}(0, 1),\n",
    "$$\n",
    "  \n",
    "とする。ただし$\\mathbf{a_{t}}^\\top \\in \\mathbb{R}, \\sigma_{t} \\in \\mathbb{R}_{>0}, b_{t} \\in \\mathbb{R}$はモデルのパラメータ。  \n",
    "状態空間モデルのパラメータをまとめて$\\Theta_{t} = (\\mathbf{\\mu_{0}}, \\mathbf{\\Sigma_{0}}, \\mathbf{F_{t}}, \\mathbf{g_{t}}, \\mathbf{a_{t}}, b_{t}, \\sigma_{t}), \\forall{t} > 0$とする。古典的な設定では、パラメータは時変量なので$\\Theta_{t} = \\Theta, \\forall{t} > 0$となる。  \n",
    "パラメータを学習させる古典的な方法は最尤推定で、\n",
    "  \n",
    "$$\n",
    "\\Theta_{1:T}^{*} = \\text{argmax}_{\\Theta_{1:T}}p_{ss}(z_{1:T} |\\Theta_{1:T}), \\\\\n",
    "p_{ss} = p(z_{1}|\\Theta{1}) \\prod_{t=2}^{T} p(z_{t}|z_{1:t-1}, \\Theta_{1:t}) = \\int{p(\\mathbf{l_{0}})\\Biggl\\lbrack{\\prod_{t=1}^{T}p(z_{t}|\\mathbf{l_{t}})p(\\mathbf{l}_{t}|\\mathbf{l}_{t-1})}}\\Biggr \\rbrack\n",
    "$$\n",
    "  \n",
    "複数の時系列に対してパラメータの推定を行うとき、パラメータはそれぞれの時系列に対して独立に推定させるため、複数の時系列に渡る情報を共有できない。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep State Space Model\n",
    "  \n",
    "$$\n",
    "\\Theta_{t}^{(i)} = \\Psi(\\mathbf{x}_{1:t}^{(i)}, \\Phi)\n",
    "$$\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. どうやって有効だと検証した？\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 議論はある？\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 次に読むべき論文は？\n",
    "* [A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning](https://arxiv.org/abs/1710.05741)(most relevant)\n",
    "* [Structured Inference Networks for Nonlinear State Space Models](https://arxiv.org/abs/1609.09869)\n",
    "* [Time-series extreme event forecasting with neural networks at Uber](https://www.uber.com/blog/research/time-series-extreme-event-forecasting-with-neural-networks-at-uber)\n",
    "* [State Space LSTM Models with Particle MCMC Inference](https://arxiv.org/abs/1711.11179)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 実装\n",
    "https://github.com/awslabs/gluonts  \n",
    "(特にsrc/gluonts/mx/model/deepstate/_network.py)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
